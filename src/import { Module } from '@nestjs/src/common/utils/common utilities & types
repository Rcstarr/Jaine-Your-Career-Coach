import OpenAI from 'openai';

const client = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

export async function llmChat(messages: {role:'system'|'user'|'assistant', content:string}[], model = process.env.OPENAI_MODEL || 'gpt-4o-mini') {
  const resp = await client.chat.completions.create({
    model,
    messages,
    temperature: 0.4,
    max_tokens: 600,
  });
  return resp.choices?.[0]?.message?.content?.trim() || '';
}
